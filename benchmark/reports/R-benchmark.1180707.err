+ module purge
+ local __lmod_my_status
+ local __lmod_sh_dbg
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_sh_dbg=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for Lmod's output
unload bsc/1.0 (PATH, MANPATH)
Shell debugging restarted
+ return 0
+ module load singularity
+ local __lmod_my_status
+ local __lmod_sh_dbg
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_sh_dbg=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for Lmod's output
load SINGULARITY/3.11.5 (PATH)
Shell debugging restarted
+ return 0
+ GPUS_PER_NODE=4
+ NNODES=2
++ scontrol show hostnames 'as07r1b[15-16]'
++ head -n 1
+ MASTER_ADDR=as07r1b15
+ MASTER_PORT=6000
+ echo 'NODES: 2'
+ LAUNCHER='python -u -m torch.distributed.run     --nproc_per_node 4     --nnodes 2     --node_rank $SLURM_PROCID     --rdzv_endpoint as07r1b15:6000     --rdzv_backend c10d     --max_restarts 0     --role $(hostname -s|tr -dc '\''0-9'\''):     --tee 3     '
+ PYTHON_FILE=/home/upc/upc580327/MN5-Distributed-PyTorch/benchmark/all_reduce_benchmark.py
+ export 'CMD=python -u -m torch.distributed.run     --nproc_per_node 4     --nnodes 2     --node_rank $SLURM_PROCID     --rdzv_endpoint as07r1b15:6000     --rdzv_backend c10d     --max_restarts 0     --role $(hostname -s|tr -dc '\''0-9'\''):     --tee 3      /home/upc/upc580327/MN5-Distributed-PyTorch/benchmark/all_reduce_benchmark.py'
+ CMD='python -u -m torch.distributed.run     --nproc_per_node 4     --nnodes 2     --node_rank $SLURM_PROCID     --rdzv_endpoint as07r1b15:6000     --rdzv_backend c10d     --max_restarts 0     --role $(hostname -s|tr -dc '\''0-9'\''):     --tee 3      /home/upc/upc580327/MN5-Distributed-PyTorch/benchmark/all_reduce_benchmark.py'
+ echo python -u -m torch.distributed.run --nproc_per_node 4 --nnodes 2 --node_rank '$SLURM_PROCID' --rdzv_endpoint as07r1b15:6000 --rdzv_backend c10d --max_restarts 0 --role '$(hostname' '-s|tr' -dc ''\''0-9'\''):' --tee 3 /home/upc/upc580327/MN5-Distributed-PyTorch/benchmark/all_reduce_benchmark.py
+ SRUN_ARGS='     --cpus-per-task 80     --jobid 1180707     --wait 60     '
+ SINGULARITY_CONTAINER=/home/upc/upc580327/MN5-Distributed-PyTorch/mn5_pytorch.sif
+ SINGULARITY_ARGS='     --bind /home/upc/upc580327/MN5-Distributed-PyTorch     /home/upc/upc580327/MN5-Distributed-PyTorch/mn5_pytorch.sif     '
+ srun --cpus-per-task 80 --jobid 1180707 --wait 60 singularity exec --nv --bind /home/upc/upc580327/MN5-Distributed-PyTorch /home/upc/upc580327/MN5-Distributed-PyTorch/mn5_pytorch.sif bash -c 'python -u -m torch.distributed.run     --nproc_per_node 4     --nnodes 2     --node_rank $SLURM_PROCID     --rdzv_endpoint as07r1b15:6000     --rdzv_backend c10d     --max_restarts 0     --role $(hostname -s|tr -dc '\''0-9'\''):     --tee 3      /home/upc/upc580327/MN5-Distributed-PyTorch/benchmark/all_reduce_benchmark.py'
15:4: not a valid test operator:  
15:4: not a valid test operator: 12.4
21:4: not a valid test operator: (
21:4: not a valid test operator: 535.86.10
15:4: not a valid test operator:  
15:4: not a valid test operator: 12.4
21:4: not a valid test operator: (
21:4: not a valid test operator: 535.86.10
++ date
+ echo 'END TIME: Sun Apr 28 19:39:54 CEST 2024'
